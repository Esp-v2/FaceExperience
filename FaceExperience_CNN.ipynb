{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceExperience_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq9hvgg8zQ2p"
      },
      "source": [
        "**CNNによる2次元顔画像表情判定**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlyygK5u_LGY",
        "outputId": "9a05c158-9616-42f6-9f0f-c671d5ac5402"
      },
      "source": [
        "!ps aux\n",
        "!kill -9 <pid>"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n",
            "root           1  0.2  0.0    992     4 ?        Ss   22:37   0:00 /sbin/docker-\n",
            "root           7  0.2  0.3 337764 48264 ?        Sl   22:37   0:00 /tools/node/b\n",
            "root          17  0.2  0.0  35888  4896 ?        Ss   22:37   0:00 tail -n +0 -F\n",
            "root          39  0.2  0.3 160356 41792 ?        S    22:37   0:00 python3 /usr/\n",
            "root          52  0.7  0.4 193892 60284 ?        Sl   22:38   0:01 /usr/bin/pyth\n",
            "root          53  0.0  0.0 706824  7352 ?        Sl   22:38   0:00 /usr/local/bi\n",
            "root          64  9.2  2.9 2032376 388636 ?      Ssl  22:40   0:03 /usr/bin/pyth\n",
            "root          84  0.2  0.1 127644 14916 ?        Sl   22:40   0:00 /usr/bin/pyth\n",
            "root         112  0.0  0.0  59040  6448 ?        R    22:40   0:00 ps aux\n",
            "/bin/bash: -c: line 0: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 0: `kill -9 <pid>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNFBa-nYFNkR",
        "outputId": "89092643-a22c-4a9c-c47e-dc13282069b9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XKF13tnERHW"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Flatten,MaxPooling2D,Conv2D\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emmlcpStzibv"
      },
      "source": [
        "**訓練画像、検証画像、テスト画像のディレクトリ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4YNFRZ-FHHp"
      },
      "source": [
        "classes = ['angry', 'disgust','fear','happy','neutral','sad','suprise']\n",
        "nb_classes = len(classes)\n",
        "#batch_size_for_data_generator = 20\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/kaggle/Facial Experience'\n",
        "\n",
        "train_dir = base_dir+'/train'\n",
        "validation_dir = base_dir+'/valid'\n",
        "test_dir = base_dir+'/test'\n",
        "\n",
        "img_rows, img_cols = 48, 48"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1DoKb8vJULr"
      },
      "source": [
        "os.path.join(base_dir,'path')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3U9Oi0z0Ob9"
      },
      "source": [
        "**ImageDataGeneratorを使って画像データを拡張する**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZWcxF46V24h"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "train_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                                    target_size=(img_rows, img_cols),\n",
        "                                                    color_mode='rgb',\n",
        "                                                    classes=classes,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    batch_size=1117,\n",
        "                                                    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuGxBj_f1yPP"
      },
      "source": [
        "train 84892枚\n",
        "2x2x19x1117\n",
        "バッジサイズ2048"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRDqyGVIWFjm",
        "outputId": "956e7542-00ce-4bb9-e38a-506c7e289d9f"
      },
      "source": [
        "valid_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "validation_generator = valid_datagen.flow_from_directory(directory=validation_dir,\n",
        "                                                        target_size=(img_rows, img_cols),\n",
        "                                                        color_mode='rgb',\n",
        "                                                        classes=classes,\n",
        "                                                        class_mode='categorical',\n",
        "                                                        batch_size=131,\n",
        "                                                        shuffle=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21615 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7EkjT3x2bk5"
      },
      "source": [
        "valid 21615枚 3x5x11x131 バッジサイズ2048"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLSUpDGs2ifm"
      },
      "source": [
        "**CNNモデル**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSQuX9v64IAT"
      },
      "source": [
        "なんで512?→特に理由なし1024でもなんでもいい\n",
        "\n",
        "dropoutの役割→層から層への伝達の際に出力データを意図的に0とする事で、訓練データに過剰適合する問題を回避する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIg6Ng3d52cL"
      },
      "source": [
        "出力層\n",
        "二値分類→sigmoid\n",
        "他クラス分類→softmax\n",
        "回帰分類→恒等関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3XQUcKsfq5x"
      },
      "source": [
        "leaky relu\n",
        "\n",
        "relu関数においてx<0のとき正の傾きを与える"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkvDQZF0n4gY"
      },
      "source": [
        "過学習を起こしたら、入力層にDropout率0.2、隠れ層に0.5を適用する\n",
        "\n",
        "https://deepage.net/deep_learning/2016/10/17/deeplearning_dropout.html#tflearn%E3%81%AE%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQPRXwdarKaH",
        "outputId": "164593e0-02e9-4551-a3a7-147736eb2bba"
      },
      "source": [
        "from keras.layers import BatchNormalization\n",
        "#first layer\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), input_shape = (img_rows, img_cols, 3) ,padding='same'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "#second layer\n",
        "model.add(Conv2D(32, (3,3), padding='same' ))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "#regularization\n",
        "model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "#thirt layer\n",
        "model.add(Conv2D(64, (3,3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "#fourth layer\n",
        "model.add(Conv2D(64, (3,3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "#classification layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 48, 48, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 48, 48, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 48, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               4719104   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 3591      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 7)                 0         \n",
            "=================================================================\n",
            "Total params: 4,791,079\n",
            "Trainable params: 4,789,671\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szvIOUtftc2R"
      },
      "source": [
        "miniVGGnet\n",
        "https://github.com/matvi/miniVGGNet/blob/master/cnn/MiniVGGNet.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH0jxO1oWNjC"
      },
      "source": [
        "# model=Sequential()\n",
        "# # 畳み込み層\n",
        "# model.add(Conv2D(32, (3, 3), activation='relu',input_shape=(img_rows, img_cols, 3)))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# # 全結合層\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# # 出力層\n",
        "# model.add(Dense(nb_classes, activation='softmax'))\n",
        "          \n",
        "# model.summary()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j8jbWX67fgr"
      },
      "source": [
        "モデル参照先\n",
        "https://sciresol.s3.us-east-2.amazonaws.com/IJST/Articles/2019/Issue-24/Article9.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJb_lDZoWX96",
        "outputId": "fcff6c33-4a09-4800-dcaa-7203c7d8d6fe"
      },
      "source": [
        "opt = Adam(lr=0.001, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',optimizer= opt, metrics=['acc'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCQQwsls4aKW"
      },
      "source": [
        "**コールバックを使った学習**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuTqNiABCVar"
      },
      "source": [
        "hdf5_file = os.path.join(base_dir, 'model.hdf5')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKIS8wpnzFBa"
      },
      "source": [
        "再度ここから"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "OZy9RFVmBks9",
        "outputId": "0c3a03b5-f75d-42fa-ec1a-3d86a753c8d0"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "modelCheckpoint = ModelCheckpoint(filepath = hdf5_file,\n",
        "                                  monitor='loss',\n",
        "                                  verbose=1,\n",
        "                                  save_best_only=True,\n",
        "                                  save_weights_only=False,\n",
        "                                  mode='min',\n",
        "                                  period=1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ab34c175241e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m modelCheckpoint = ModelCheckpoint(filepath = hdf5_file,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                   \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                   \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hdf5_file' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwpOn_MdWq91"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=76,\n",
        "                    epochs=5,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=165,\n",
        "                    callbacks=[modelCheckpoint],\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RWIBKMEWxTo"
      },
      "source": [
        "model.save(hdf5_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB1RGpShZAxx"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT-olribZELf"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILeMIAeoZE5L"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io1A1fx02E3p"
      },
      "source": [
        "**テスト**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcPSD3HajYzT"
      },
      "source": [
        "#test_datagen = ImageDataGenerator(rescale=1.0 / 255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mo7v1tA2IDM"
      },
      "source": [
        "#model=keras.models.load_model(hdf5_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbJwdZZoZJqz"
      },
      "source": [
        "# import numpy as np\n",
        "# test_generator = test_datagen.flow_from_directory(directory=test_dir,\n",
        "#                                                   target_size=(img_rows, img_cols),\n",
        "#                                                   color_mode='rgb',\n",
        "#                                                   classes=classes,\n",
        "#                                                   class_mode='categorical',\n",
        "#                                                   batch_size=32,\n",
        "#                                                   shuffle=False)\n",
        "\n",
        "# test_steps_per_Epoch = np.math.ceil(test_generator.samples / test_generator.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eta-fthmqFhI"
      },
      "source": [
        "# predictions = model.predict_generator(test_generator, steps=test_steps_per_Epoch)\n",
        "# # Get most likely class\n",
        "# predicted_classes = np.argmax(predictions, axis=1)\n",
        "# # Ground-Truthクラスとクラスラベルを取得する\n",
        "# true_classes = test_generator.classes\n",
        "# class_labels = list(test_generator.class_indices.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c3S0sPF3z0W"
      },
      "source": [
        "適合率（precision）: precision_score()：実際に正/正と予測\n",
        "\n",
        "再現率（recall）: recall_score()：正と予測/実際に正\n",
        "\n",
        "F1値（F1-measure）: f1_score()：0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9ysbq3h8c_B"
      },
      "source": [
        "# from sklearn import metrics\n",
        "# # scikit-learnを使用して統計を取得する\n",
        "# report = metrics.classification_report(true_classes, \n",
        "#                                        predicted_classes, \n",
        "#                                        labels=np.arange(len(classes)),\n",
        "#                                        target_names=classes)\n",
        "# print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k-jUgsC5b3Y"
      },
      "source": [
        "**参考**\n",
        "\n",
        "\n",
        "*   [Keras / CNN] 多クラス画像分類 --- ラーメンの味分類\n",
        "\n",
        "    https://qiita.com/Phoeboooo/items/cfe8560fe8a285855340\n"
      ]
    }
  ]
}